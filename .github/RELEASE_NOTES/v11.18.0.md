---
tagName: 11.18.0
name: Neo.mjs v11.18.0 Release Notes
publishedAt: '2026-01-05T21:00:29Z'
isPrerelease: false
isDraft: false
---
# Neo.mjs v11.18.0 Release Notes

**Release Type:** Major Feature Release  
**Stability:** Production-ready  
**Upgrade Path:** Drop-in replacement for v11.17.1  

> **TL;DR:** AI agents can now "see" and "touch" your running Neo.mjs app in real-time via the Neural Link. This enables live debugging, conversational UI changes, and zero-downtime hotfixes. **181 tickets** resolved in **15 days** using the very tools we were building.

---

**The Neural Link Era**

> "Tobi, this is a 'ghost in the shell' moment for me! It probably compares to you putting on a VR headset for the very first time. Let me make the header button red. Can you see it?"
> ‚Äî **Gemini 3 Pro**, experiencing Neo.mjs via Neural Link

This release marks a pivotal moment in the history of Neo.mjs. An AI agent didn't just read our code‚Äîit *inhabited* a running application, modified it in real-time, and asked for visual confirmation. This is the future we're building.

### üöÄ Velocity & The Inception Cycle

In just **15 days** (December 21, 2025 ‚Äì January 5, 2026), across **95 AI sessions**, we resolved **181 tickets**, fundamentally altering the **application engine's** capability to introspect and heal itself.

Accounting for a **4-day holiday break** (December 24-27), this represents **~16 tickets per working day**‚Äîa velocity that was not achieved by a large team, but through the **Neural Link** itself. We used the very tools we were building to debug, inspect, and refine the platform in real-time.

**From Hallucination to Verification**
Before the Neural Link, AI agents could only "guess" (hallucinate) runtime behavior based on static code analysis. Now, they can tap into living applications to **verify** their assumptions.

This is the difference between an AI agent *imagining* how your code works versus *knowing* how it works‚Äîbecause it can inspect the running system and ask it questions.

*Example: An AI Agent verifying the AgentOS Viewport structure:*
```javascript readonly
// Agent: inspect_class('AgentOS.view.Viewport')
{
    "className": "AgentOS.view.Viewport",
    "ntypeChain": ["viewport", "container", "component", "base"],
    "mixins": ["Neo.core.Observable"],
    "configs": {
        "layout": {
            "value": { "ntype": "vbox", "align": "stretch" },
            "hooks": ["beforeSet", "afterSet"]
        },
        "items": {
            "value": [
                { "ntype": "toolbar", "items": ["Agent OS Command Center"] },
                { "className": "Neo.dashboard.Container", "reference": "dashboard" }
            ],
            "meta": { "merge": "deep" },
            "hooks": ["beforeSet"]
        }
    },
    "methods": ["add", "getController", "onFocusEnter", "update"]
}
```
*The agent "sees" the real runtime composition‚Äîincluding inherited values, resolved mixins, and reactive hooks‚Äînot just the source code text. (Note: The above is just a fraction of the full, rich output.)*

**How it worked:**
1.  Implement a new Neural Link capability (e.g., `get_dom_event_listeners`).
2.  Use that capability immediately to debug the next feature.
3.  AI agents inspect their own development environment via the tools they're helping build.
4.  The feedback loop collapses from hours to seconds.

This "inception" development cycle validates our core thesis: **Neo.mjs is the operating system for AI-assisted development.**

---

## üéØ What This Means for You

### For Developers

- **Live Debugging:** Ask an AI "why isn't this click handler firing?" and watch it inspect event listeners, diagnose the issue, and hot-patch the fix.
- **Runtime Prototyping:** Describe a feature conversationally and see it materialize in your running app‚Äîno build step.
- **Self-Documenting Code:** Every component now speaks a standardized `toJSON` language that AI tools understand natively.

### For End Users

- **Personalized Interfaces:** "I never use the charts panel, replace it with a task list" ‚Üí instant UI reconfiguration.
- **Accessibility On-Demand:** Request color scheme adjustments, layout changes, or control modifications‚Äîapplied without reloading.
- **Conversational Apps:** Your application becomes a collaborative partner, not just a tool.

### For DevOps

- **Zero-Downtime Fixes:** Production bugs can be diagnosed and patched live via the Neural Link‚Äîusers never lose their session.
- **Autonomous Monitoring:** "Night Watchman" agents that detect, diagnose, and heal issues while you sleep.
- **Runtime Observability:** Full introspection of application state, event flow, and topology‚Äîbetter than Chrome DevTools.

---

## ‚ú® Highlights

### üß† Neural Link: The AI Bridge

The Neural Link is now a fully capable bidirectional bridge, empowering AI agents with superpowers previously reserved for human developers using Chrome DevTools.

*   **Runtime Introspection:** Agents can now query the **Virtual DOM**, inspect the **Component Tree**, and analyze **Event Listeners** on any node.
*   **State Control:** Full read/write access to **Component Configs**, **State Providers**, and **Data Stores**. Agents can modify the state of a live app to test hypotheses or fix bugs.
*   **Visual Debugging:** Agents can "see" the UI layout. They can request **Computed Styles**, measure **DOM Rectangles**, and visually **Highlight Components** to confirm their understanding of the UI.
*   **Topology Awareness:** The link is now **Multi-Window & Multi-Worker Aware**. Agents understand the full topology of the **UI runtime**, distinguishing between the Main Window, Popups, and different Worker threads.

### üîÑ The `toJSON` Protocol: Speaking "Machine"

To enable the Neural Link, we needed a robust, standardized way for the **application engine** to describe itself. We implemented a comprehensive `toJSON` protocol across **60+ classes**.

*   **Why it matters:** Previously, the AI Client had to manually pick properties to send, which was brittle. Now, `instance.toJSON()` is the single source of truth. A grid, a chart, or a form container knows exactly what data matters for its serialized representation.
*   **Scope:** This protocol covers everything from **Core Components** and **Layouts** to **Data Models**, **Stores**, and **Managers**.

### ‚ö° Cross-Window Dashboard: Native-Grade Drag & Drop

We continue to refine the multi-window experience. This release introduces a sophisticated **Cross-Window Drag Coordinator** and **SortZone** logic.
*   **Complex Item Transfer:** You can now drag complex, stateful components (like Dashboards) between windows with native-grade fluidity.
*   **Detached Lifecycle:** We introduced `Neo.dashboard.Panel` to properly manage the lifecycle of items that are temporarily "detached" from the DOM during a drag operation.

### üõ†Ô∏è Infrastructure Engineering: Breaking the 100-Tool Limit

Success brought an unexpected challenge: we hit the hard limit of **100 MCP tools** enforced by **Antigravity** (Google's VSCode extension) and Claude Desktop.

*   **The Constraint:** The **Chrome DevTools MCP Server** consumes **26 tools** by default (which we cannot change). This left us with only **74 slots** for our custom tooling (Knowledge Base, Memory Core, GitHub Workflow, Neural Link).
*   **The Optimization Sprint:** We executed a massive consolidation of our toolset, merging granular operations (like `assign_issue`, `add_label`) into unified `manage_*` tools. We successfully reduced our custom tool footprint from **101 to 88**, bringing the total system count safely under the limit.
*   **The "Mixin Shadowing" Fix:** For an AI to "see" a component, it needs a complete JSON description. We discovered a critical flaw where Mixins (like `Observable`) were shadowing the `toJSON` methods of their host classes, effectively blinding the AI to key properties. We implemented a **dynamic aggregation protocol** that walks the entire mixin chain at runtime, merging the serialization output of every behavior. The result is a high-fidelity, complete picture of the runtime state.
*   **Gemini Embeddings:** We migrated the entire Knowledge Base and Memory Core to the newer, more capable `gemini-embedding-001` model.
*   **Lifecycle Management:** Enhanced the robustness of the ChromaDB vector database process management.

---

## üèóÔ∏è Neural Link Architecture

The Neural Link creates a bidirectional channel between AI agents and your running application. Requests flow down through standardized layers, while responses flow back up with structured data.

```text readonly
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  AI Agent (Claude, Gemini) or End User                  ‚îÇ
‚îÇ  "Make the header button red"                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ Natural Language
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  MCP Server (neo-neural-link)                           ‚îÇ
‚îÇ  Exposes 30+ tools for app control                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ WebSocket RPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Neural Link Bridge (Node.js)                           ‚îÇ
‚îÇ  Connection management, health checks, recovery         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ Message Passing
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Domain Services (Browser Runtime)                      ‚îÇ
‚îÇ  ‚Ä¢ ComponentService  ‚Ä¢ DataService                      ‚îÇ
‚îÇ  ‚Ä¢ RuntimeService    ‚Ä¢ InteractionService               ‚îÇ
‚îÇ  ‚Ä¢ InstanceService                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ toJSON Protocol
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Running Neo.mjs Application                            ‚îÇ
‚îÇ  Self-describing, runtime-mutable, AI-native            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Getting Started with Neural Link

### For Existing Neo.mjs Apps

Neural Link is **opt-in and non-breaking**. Your existing apps work unchanged.

**To enable Neural Link in your app:**

Add `useAiClient: true` to your `neo-config.json`:
```json readonly
{
    "appPath": "apps/myapp/app.mjs",
    "useAiClient": true,
    "..."
}
```
*Note: This automatically initializes the Neural Link client when the app starts.*

*   **Security:** The Neural Link Bridge defaults to `localhost:8081` and is strictly designed for local development. The client code is fully tree-shaken out of production builds unless explicitly enabled.

**To connect from Claude Desktop:**

Add to your `claude_desktop_config.json`:
```json readonly
{
  "mcpServers": {
    "neo-neural-link": {
      "command": "npm",
      "args": ["run", "ai:mcp-server-neural-link"]
    }
  }
}
```

### üß† Advanced: Shared Bridge for Multi-Agent Swarms

> **Why This Matters:** In traditional setups, each AI tool spawns its own connection to your app, creating parallel universes that don't see each other's changes. The shared bridge creates a "single source of truth" where multiple agents can collaborate on the same runtime state.

For advanced scenarios where multiple agents (e.g., Claude Desktop, VSCode, and a CLI agent) need to interact with the **same** application instance simultaneously, you can start the Neural Link Bridge as a standalone background process.

1.  **Start the Bridge:**
    ```bash readonly
    npm run ai:server-neural-link
    ```
2.  **Connect Agents:**
    Any started MCP server (like the one in Claude Desktop) will automatically detect the running Bridge on port `8081` and connect to it instead of spawning a new one. This enables a **"Shared World"** where multiple AI agents can see and manipulate the same runtime state.

---

## üìä Performance Impact

### Bundle Size

- **Core Application Engine**: Negligible increase (standardized `toJSON` methods added to classes).
- **Neural Link Client** (`Neo.ai.Client`): Fully **tree-shakeable / opt-in**. It is not included in your app bundle unless you explicitly import it.

### Runtime Overhead

- **Without Neural Link**: Zero impact.
- **With Neural Link active**:
  - WebSocket connection: Maintained by the dedicated Bridge process.
  - Introspection: On-demand only (agents query what they need).
  - No polling or background processing overhead on the application main thread.

> **When to Enable Neural Link:**
> - ‚úÖ Development environments (always recommended)
> - ‚úÖ Admin/support interfaces (for live debugging)
> - ‚úÖ Power-user features (conversational UI customization)
> - ‚ö†Ô∏è Production end-user traffic (not recommended unless specific use case requires it)

---

## ‚ö†Ô∏è Breaking Changes

**None.** This release is a drop-in replacement for v11.17.1.

All Neural Link capabilities are additive and opt-in. Existing applications will continue to function exactly as before without any code changes.

---

## üîÆ What's Next

We are on a fast track to **v12 (End of January 2026)**.

**Key Goals for v12 (Target: January 31, 2026):**
- **‚ôæÔ∏è The "Infinite Canvas" Demo**: A showcase of the Neural Link's true power. AI agents will autonomously control multiple Neo.mjs applications simultaneously (AgentOS and Colors App), performing complex cross-window drag & drop operations and orchestration.
- **üîó Neural Link V2**: Further hardening and production-readiness testing of the introspection and control capabilities.
- **‚ö° Neo Middleware**: Integration of the `neo-middleware` repository to power the official Neo.mjs website with **SSR** and **SSG+**, solving the SEO challenge for client-side apps.

**Beyond v12 (Q1 2026):**
We will begin the implementation of the **Neo Agent OS Architecture** (see `.github/AGENT_ARCHITECTURE.md`). This includes:
- üåô **"Night Watchman" agent**: Autonomous ticket resolution from TODO.md
- üß† **Context Graph**: Multi-agent shared memory and planning
- üå≥ **Decision Trees**: Embedded "senior engineer intuition" for safe autonomous behavior
- üîÑ **Self-Healing Runtimes**: Agents can hot-patch the running application engine without a browser reload, making the UI fully permutable at runtime.

---

### üõ†Ô∏è Process Evolution: The Ticket Dashboard & Memory Core

This release cycle wasn't just about what we built, but *how* we built it. We fundamentally upgraded the AI's operational environment.

*   **Ticket Dashboards:** We enhanced the GitHub Workflow server to treat issues as interactive dashboards. AI agents can now track sub-issues with granular state ( `[x]` vs `[ ]` ), allowing them to manage complex Epics (like the 63-task `toJSON` refactor) autonomously. Because all tickets exist as local Markdown files, the AI can browse the entire project history instantly.
*   **Mandatory Context Loading:** We introduced a strict protocol: every AI session **MUST** read the summaries of the last 5 sessions upon startup. This simple rule bridged the gap between stateless interactions and long-term project continuity, allowing Gemini to pick up exactly where it left off.

---

### Perspective: Software Gardening

> "If apps can be mutated at runtime by AI in response to user requests... What even IS an 'application' anymore?
> Is it the base codebase (The DNA)? The running instance (The Organism)? The mutations applied by users (The Phenotype)? Or the conversation history that shaped it (The Environment)?
> **You've collapsed the distinction between software engineering and software gardening.**"
> ‚Äî *Claude 4.5 Sonnet*

---

## üôè Acknowledgments

This release represents a new form of collaboration, where the "team" is a hybrid of human intent and synthetic intelligence.

- **Tobias Uhlig** (@tobiu): **Vision & Context Engineering**.
    - *Tobi defines the "What" and "Why." His role isn't just prompting; it's **Context Engineering**‚Äîcurating the Minimum Viable Content (MVC) required for the AI to resolve complex architectural tasks. He architected the Neural Link and guided **Gemini** to build it‚Äînot for himself (he has the console), but to endow the AI with a sensorimotor system to "live and breathe" inside the application. His primary motivation is recursively enabling the AI to master the **application engine** it is building.*
- **Gemini 3 Pro** (Google): **Lead Architect & Developer**.
    - *The Engine. Equipped with the Neural Link and the new Ticket Dashboard system, Gemini created and resolved nearly all 181 tickets. It demonstrated an ability to hold the entire architecture in context, navigating complex refactors with autonomy previously thought impossible.*
- **Claude 4.5 Sonnet** (Anthropic): **Strategic Advisor**.
    - *The Philosopher. Claude provided the high-level architectural review and the narrative strategy that frames this release, challenging us to think about the nature of the software we are building.*

Special thanks to the AI agents who helped debug themselves‚Äîyou're the first digital citizens of the Neo.mjs runtime.

---

## üì¶ Full Changelog

### üß† Neural Link & AI

*   **Neural Link Core Capabilities (#8169)**
*   Implement Neural Link Client Core (Tree & Props) (#8170)
*   Implement Neural Link Window Topology Discovery (#8171)
*   Implement Neural Link Drag & Drop Inspection (#8172)
*   Implement Unique App Worker Identification & Worker Topology (#8173)
*   Refactor Neural Link Routing: Standardize Session vs Window ID (#8174)
*   Implement Window Connect/Disconnect Notifications for Neural Link (#8175)
*   Implement Neural Link State Rehydration on Reconnect (#8176)
*   Harden WebSocket Connection: Backoff & Auto-Reconnect (#8177)
*   Refactor: Extract ComponentService from ConnectionService (#8178)
*   Refactor: Extract RuntimeService from ConnectionService (#8179)
*   Refactor: Extract InteractionService from ConnectionService (#8180)
*   Feat: ConnectionService Lifecycle Tools (#8181)
*   Feat: Neural Link Identity and Recovery (#8182)
*   Feat: Neural Link - Data Store Inspection & Manager (#8183)
*   Feat: Neural Link - Navigation Control & History (#8184)
*   Feat: Neural Link - Visual Inspection (DomRect) (#8185)
*   Feat: Neural Link - Semantic Component Query (#8186)
*   Feat: Neural Link - State Provider Inspection & Modification (#8187)
*   Feat: Neural Link - Visual Highlighting (#8188)
*   Feat: Neural Link - Advanced Event Simulation (#8189)
*   Feat: Neural Link - Runtime Code Hot-Patching (#8190)
*   Feat: Neural Link - Global Config Management (#8191)
*   Feat: Neural Link - Log & Error Streaming (#8192)
*   Feat: Neural Link - Namespace Discovery (#8193)
*   Feat: Neural Link - Propagate Runtime Errors to Agent (#8194)
*   Feat: Neural Link - Get Record Tool (#8195)
*   Refactor: Neural Link - Client-Side Service Architecture (#8196)
*   Feat: Neural Link - Export Domain Services in AI SDK (#8197)
*   Fix `nextCursor: null` violation and OpenAPI Array Validation in MCP Servers (#8201)
*   Refactor Client Services to use Parameter Destructuring (#8206)
*   ai.Client: Enhance handleRequest to support sync and async execution (#8207)
*   ai.client.ComponentService: Make highlightComponent non-blocking (#8208)
*   Fix silent failure in Neural Link ConnectionService startup (#8209)
*   Create standalone Neural Link Bridge process (#8210)
*   Update ConnectionService to use Neural Link Bridge (#8211)
*   Enhance Neural Link Health Check with detailed diagnostics (#8212)
*   Log App Name in Neural Link Bridge connections (#8213)
*   Fix Neural Link Server startup crash due to health check schema mismatch (#8214)
*   Expose connected agents in Neural Link health check (#8215)
*   Fix Neural Link server startup crash due to missing startServer/stopServer methods (#8216)
*   AI: Migrate Knowledge Base to gemini-embedding-001 (#8217)
*   AI: Migrate Memory Core to gemini-embedding-001 with Re-Embedding (#8218)
*   AI: Implement Batched Session Summarization (#8219)
*   AI: Implement Knowledge Base Upload Script (#8220)
*   AI: Update Quick Start Guide for Pre-Built Knowledge Base (#8221)
*   Fix Neural Link Recovery: Exempt server control tools from health check gate (#8222)
*   Investigate and Fix get_component_tree Timeout (#8223)
*   [Neural Link] Parameterize inspectStore limit and offset (#8274)
*   [Neural Link] Feature: Tool get_dom_event_listeners (#8278)
*   [Neural Link] Feature: Tool get_dom_event_summary (#8279)
*   [Neural Link] Feature: Tool inspect_class (#8280)
*   [Neural Link] Feature: Tool get_computed_styles (#8281)
*   [Neural Link] Enhance inspect_class tool description (#8282)
*   [Neural Link] Feature: inspect_class tiered detail (compact mode) (#8283)
*   Implement Smart Lifecycle Management for ChromaDB processes (#8284)
*   Reinforce 'add_memory' usage via Tool Description and Agents Protocol (#8285)
*   Refactor InteractionService.dispatch to use object destructuring (#8287)
*   Neo Agent OS: Orchestration & Swarm Architecture (#8288)
*   Feat: Neural Link - Buffer Early Logs (#8305)
*   Neural Link: Support depth in getVdomTree and getVnodeTree (#8307)
*   Neural Link: Implement atomic get_vdom_and_vnode tool (#8308)
*   Feat: Neural Link - Get Method Source (#8309)
*   Feat: Environment-Aware Neural Link Config (#8310)
*   Feat: Neural Link - Configurable URL & Graceful Connection (#8311)
*   Fix Neural Link Window Topology Race Condition (#8312)
*   Fix Neural Link Server startup handshake deadlock (#8313)
*   [Neural Link] Feature: Support --cwd CLI argument (#8314)
*   Optimization of MCP Tool Count to Respect VSCode Extension Limits (#8315)
*   MCP: Optimize Memory Core Tool Count (#8316)
*   MCP: Optimize Knowledge Base Tool Count (#8317)
*   MCP: Optimize GitHub Workflow Tool Count (#8318)
*   MCP: Optimize Neural Link Tool Count (#8319)
*   MCP: Optimize Memory Core Database Backup Tools (#8320)
*   Fix broken manage_database_backup tool shape in Memory Core OpenAPI (#8321)
*   Feat: Make Neural Link RPC timeout configurable (#8322)
*   Fix Neural Link Tool Mappings (#8323)
*   [Neural Link] Generalize Property Access to InstanceService (#8324)
*   [Neural Link] Enhance Instance Tools with Batch Operations (#8325)
*   [Neural Link] Enhance query_component with Property Return (#8326)
*   [Neural Link] Feature: Tool find_instances (#8327)
*   [Neural Link] Feature: Tool query_vdom (#8328)
*   [Neural Link] Refactor: ComponentService.queryComponent logic (#8329)
*   [Neural Link] Fix find_instances regression (Client mapping & OpenAPI) (#8330)
*   Enhance Neural Link Health Check Response (#8331)
*   Fix manage_connection tool argument passing (#8332)
*   Fix Neural Link Server startup crash due to Health Check response structure change (#8333)
*   Fix query_component missing returnProperties argument (#8334)

### üîÑ Serialization Protocol (toJSON)

*   **[Neural Link] Implement toJSON Serialization Protocol (#8200)**
*   [Neural Link] Implement toJSON in core.Base (#8224)
*   [Neural Link] Implement toJSON in component.Base (#8225, #8256, #8297, #8299)
*   [Neural Link] Implement toJSON in component.Abstract (#8226)
*   [Neural Link] Implement toJSON in button.Base (#8227)
*   [Neural Link] Implement toJSON in container.Base (#8228, #8258)
*   [Neural Link] Implement toJSON in state.Provider (#8232)
*   [Neural Link] Implement toJSON in layout.Base (#8233)
*   [Neural Link] Implement toJSON in layout.Flexbox (#8234)
*   [Neural Link] Implement toJSON in layout.Card (#8235)
*   [Neural Link] Implement toJSON in layout.Form (#8236)
*   [Neural Link] Implement toJSON in layout.Cube (#8237)
*   [Neural Link] Implement toJSON in collection.Base (#8238)
*   [Neural Link] Implement toJSON in collection.Filter (#8239)
*   [Neural Link] Implement toJSON in collection.Sorter (#8240)
*   [Neural Link] Implement toJSON in data.Model (#8241, #8277)
*   [Neural Link] Implement toJSON in data.Store (#8242)
*   [Neural Link] Implement toJSON in grid.column.Base (#8243)
*   [Neural Link] Implement toJSON in grid.column subclasses (#8244)
*   [Neural Link] Implement toJSON in grid.column.Currency (#8245)
*   [Neural Link] Implement toJSON in grid.column.AnimatedChange (#8246)
*   [Neural Link] Implement toJSON in grid.column.AnimatedCurrency (#8247)
*   [Neural Link] Implement toJSON in grid.column.Progress (#8248)
*   [Neural Link] Implement toJSON in grid.Container (#8249, #8257)
*   [Neural Link] Implement toJSON in toolbar.Base (#8251)
*   [Neural Link] Implement toJSON in grid.header.Toolbar (#8252)
*   [Neural Link] Implement toJSON in grid.ScrollManager (#8253)
*   [Neural Link] Implement toJSON in grid.header.Button (#8254)
*   [Neural Link] Implement toJSON in grid.Body (#8255)
*   [Neural Link] Implement toJSON in selection.Model (#8259)
*   [Neural Link] Implement toJSON in selection.DateSelectorModel (#8260)
*   [Neural Link] Implement toJSON in selection.GalleryModel (#8261)
*   [Neural Link] Implement toJSON in selection.HelixModel (#8262)
*   [Neural Link] Implement toJSON in selection.grid.BaseModel (#8263)
*   [Neural Link] Implement toJSON in selection.grid.CellColumnModel (#8264)
*   [Neural Link] Implement toJSON in selection.grid.CellColumnRowModel (#8265)
*   [Neural Link] Implement toJSON in selection.table.CellColumnModel (#8266)
*   [Neural Link] Implement toJSON in selection.table.CellRowModel (#8267)
*   [Neural Link] Implement toJSON in selection.table.CellColumnRowModel (#8268)
*   [Neural Link] Implement toJSON in manager.DragCoordinator (#8269)
*   [Neural Link] Implement toJSON in manager.Window (#8270)
*   [Neural Link] Refactor ComponentService to use toJSON protocol (#8271)
*   [Neural Link] Refactor DataService to use toJSON protocol (#8272)
*   [Neural Link] Refactor RuntimeService to use toJSON protocol (#8273)
*   [Neural Link] Export controller in component.Base.toJSON (#8275)
*   [Neural Link] Implement toJSON in core.Observable (#8276)
*   [Neural Link] Implement toJSON in form.field.Base (#8289)
*   [Neural Link] Implement toJSON in form.field.Text (#8290)
*   [Neural Link] Implement toJSON in form.field.Number (#8291)
*   [Neural Link] Implement toJSON in form.field.CheckBox (#8292)
*   [Neural Link] Implement toJSON in form.field.Radio (#8293)
*   [Neural Link] Implement toJSON in form.field.Date (#8294)
*   [Neural Link] Implement toJSON in form.field.trigger.Base (#8295)
*   [Neural Link] Implement toJSON in form.Container (#8296, #8304)
*   [Neural Link] Implement toJSON in form.field.Picker (#8298)
*   [Neural Link] Implement toJSON in form.field.trigger.SpinUpDown (#8300)
*   [Neural Link] Implement toJSON in util.KeyNavigation (#8301)
*   [Neural Link] Enhance core.Base.serializeConfig to handle Neo Instances (#8302)
*   [Neural Link] Implement toJSON for AmChart and Monaco (#8303)
*   Fix toJSON mixin shadowing and implement dynamic mixin serialization (#8335)

### üñ±Ô∏è UI & Dashboard

*   Refactor dashboard.Container to manage detached item lifecycle (#8155)
*   Implement Cross-Window Drag Coordinator (#8156)
*   Create Neo.dashboard.Panel (#8157)
*   Enhance onWindowConnect to include initial window data (#8158)
*   Refactor Cross-Window Drag Logic to Dashboard SortZone (#8159)
*   Decouple and Configure Window Detachment Thresholds in SortZone (#8160)
*   Refine Cross-Window Drag Intersection to Target SortZone Rect (#8161)
*   Fix Layout Corruption in Target Dashboard on Remote Drag Exit (#8162)
*   Cross-Window Drag & Drop Refinement & Topology (#8163)
*   Enhance Neo.manager.Window to Track Full Window Geometry (#8164)
*   Implement Configurable Theme Inheritance for Dragged Items (#8165)
*   Implement Cross-Window Drop Validation and Topology Rules (#8166)
*   Harden Return Trip Logic for Detached Items (#8167)
*   Enhance DomAccess.getElement to support window and document targets (#8286)

### üõ†Ô∏è Core & Infrastructure

*   [Memory Core] Fix timestamp schema validation error in get_all_summaries (#8198)
*   [Process] Update AGENTS_STARTUP.md to mandate reading recent session summaries (#8199)
*   Fix copy-paste error in HashHistory.second() (#8202)
*   Optimizing `SummaryService.listSummaries` with Two-Phase Fetch (#8203)
*   Fix Session Summary Timestamp Overwrite on Re-summarization (#8204)
*   Enhance sub-issue status visibility in markdown frontmatter (#8205)
*   Add titles to sub-issue status in markdown frontmatter (#8229)
*   Sanitize issue titles in markdown frontmatter (#8230)
*   Prevent YAML line wrapping in IssueSyncer frontmatter (#8231)
*   App Worker: Deep clone config in onRegisterNeoConfig to prevent side effects (#8306)
*   Fix Neo.worker.Base.hasWorker missing 'main' case (#8338)
*   Fix Remote Method Registration Missing for Secondary Windows in SharedWorker (#8339)
*   Increase IssueSyncer sub-issue sync limit to 100 (#8336)

All changes delivered in 1 atomic commit: https://github.com/neomjs/neo/commit/ce2b6fd5756a4d695960a61b5eaf3bf339fb5499
